# ğŸ“š DocuMind AI - GeliÅŸmiÅŸ RAG TabanlÄ± DokÃ¼man Analiz AsistanÄ±

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.31+-red.svg)
![LangChain](https://img.shields.io/badge/LangChain-0.1+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**DeepSeek AI ve Multilingual Embeddings ile gÃ¼Ã§lendirilmiÅŸ, yerel bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸan akÄ±llÄ± dokÃ¼man soru-cevap sistemi**

[ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§](#-hÄ±zlÄ±-baÅŸlangÄ±Ã§) â€¢
[âœ¨ Ã–zellikler](#-Ã¶zellikler) â€¢
[ğŸ—ï¸ Mimari](#ï¸-mimari) â€¢
[ğŸ“– KullanÄ±m](#-kullanÄ±m) â€¢
[ğŸ”§ YapÄ±landÄ±rma](#-yapÄ±landÄ±rma)

</div>

---

## ğŸ¯ Proje HakkÄ±nda

DocuMind AI, **RAG (Retrieval-Augmented Generation)** mimarisini kullanarak PDF dokÃ¼manlarÄ±nÄ±zÄ± analiz eden ve sorularÄ±nÄ±za dokÃ¼man bazlÄ± hassas cevaplar veren bir AI asistanÄ±dÄ±r. Tamamen **yerel** olarak Ã§alÄ±ÅŸÄ±r - verileriniz asla dÄ±ÅŸarÄ±ya Ã§Ä±kmaz.

### ğŸŒŸ Neden DocuMind AI?

- âœ… **%100 Yerel**: Verileriniz gÃ¼vende, internet baÄŸlantÄ±sÄ± gereksiz
- ğŸ§  **AkÄ±llÄ± Semantik Arama**: Multilingual embedding ile TÃ¼rkÃ§e-Ä°ngilizce dokÃ¼manlarÄ± anlar
- ğŸ¯ **Hassas YanÄ±tlar**: Sadece dokÃ¼man iÃ§eriÄŸine dayalÄ± cevaplar, hallÃ¼sinasyon yok
- âš¡ **DeepSeek R1**: En gÃ¼ncel ve gÃ¼Ã§lÃ¼ aÃ§Ä±k kaynak LLM
- ğŸ¨ **Modern ArayÃ¼z**: SaaS seviyesinde kullanÄ±cÄ± deneyimi

---

## âœ¨ Ã–zellikler

### ğŸ” GeliÅŸmiÅŸ RAG Pipeline
- **PDF Ä°ÅŸleme**: PDFPlumber ile yÃ¼ksek kaliteli metin Ã§Ä±karma
- **AkÄ±llÄ± Chunking**: Recursive Character Text Splitter (1000 token, 200 overlap)
- **VektÃ¶r VeritabanÄ±**: InMemoryVectorStore ile hÄ±zlÄ± similarity search
- **Multilingual Embeddings**: `mxbai-embed-large` modeli ile TÃ¼rkÃ§e desteÄŸi

### ğŸ¤– AI Yetenekleri
| Ã–zellik | Teknoloji | AÃ§Ä±klama |
|---------|-----------|----------|
| **LLM Model** | DeepSeek-R1 (8B) | Reasoning odaklÄ± gÃ¼Ã§lÃ¼ dil modeli |
| **Embedding** | mxbai-embed-large | Ã‡ok dilli semantik arama |
| **Context Window** | 10 chunk | Top-K retrieval ile optimize edilmiÅŸ |
| **Prompt Engineering** | Custom Template | TÃ¼rkÃ§e, dokÃ¼man-odaklÄ± yanÄ±tlar |

### ğŸ¨ KullanÄ±cÄ± ArayÃ¼zÃ¼
- ğŸŒ™ **Dark Mode**: GÃ¶z yormayan gradient tema
- ğŸ’¬ **Chat Interface**: GerÃ§ek zamanlÄ± sohbet deneyimi
- ğŸ“Š **Retrieval Stats**: Åeffaf arama sonuÃ§larÄ±
- ğŸ—‘ï¸ **Session Management**: Sohbet geÃ§miÅŸi ve veritabanÄ± kontrolÃ¼
- ğŸ“± **Responsive**: Sidebar ile optimize edilmiÅŸ layout

---

## ğŸ—ï¸ Mimari

### Sistem DiagramÄ±

```mermaid
graph TB
    A[PDF Upload] -->|PDFPlumber| B[Document Loader]
    B --> C[Text Splitter<br/>1000 chunks]
    C --> D[mxbai-embed-large<br/>Embedding Model]
    D --> E[(InMemory<br/>Vector Store)]
    
    F[User Query] -->|Embedding| D
    D --> G[Similarity Search<br/>Top-K=10]
    E --> G
    G --> H[Context Documents]
    
    H --> I[DeepSeek-R1 LLM<br/>8B Parameters]
    F --> I
    I --> J[AI Response]
    
    style A fill:#667EEA
    style E fill:#10B981
    style I fill:#F59E0B
    style J fill:#EC4899
```

### ğŸ”„ RAG Pipeline AkÄ±ÅŸÄ±

1. **DokÃ¼man Ä°ÅŸleme**
   ```
   PDF â†’ PDFPlumber â†’ Raw Text â†’ RecursiveCharacterTextSplitter â†’ Chunks
   ```

2. **VektÃ¶rizasyon**
   ```
   Chunks â†’ mxbai-embed-large â†’ Vector Embeddings â†’ InMemoryVectorStore
   ```

3. **Query Ä°ÅŸleme**
   ```
   User Question â†’ Embedding â†’ Similarity Search â†’ Top-10 Chunks
   ```

4. **Cevap Ãœretimi**
   ```
   Question + Context â†’ Prompt Template â†’ DeepSeek-R1 â†’ Answer
   ```

### ğŸ§© Teknoloji Stack

| Katman | Teknoloji | Versiyon |
|--------|-----------|----------|
| **Frontend** | Streamlit | 1.31+ |
| **LLM Framework** | LangChain | 0.1+ |
| **LLM Engine** | Ollama | Latest |
| **Models** | DeepSeek-R1, mxbai-embed | 8B, 669MB |
| **Python** | 3.10+ | - |

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### ğŸ“‹ Gereksinimler

- **Python**: 3.10 veya Ã¼zeri
- **Ollama**: Yerel LLM Ã§alÄ±ÅŸtÄ±rÄ±cÄ±
- **RAM**: Minimum 8GB (16GB Ã¶nerilir)
- **Disk**: ~6GB boÅŸ alan (modeller iÃ§in)

### ğŸ”§ Kurulum

#### 1ï¸âƒ£ Ollama Kurulumu

**Windows:**
```powershell
# Ollama'yÄ± indirin ve kurun
winget install Ollama.Ollama
```

**Linux/macOS:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

#### 2ï¸âƒ£ Modelleri Ä°ndirin

```bash
# DeepSeek R1 (LLM)
ollama pull deepseek-r1:8b

# Multilingual Embedding
ollama pull mxbai-embed-large
```

#### 3ï¸âƒ£ Projeyi KlonlayÄ±n

```bash
git clone https://github.com/MustafaKocamann/Rag-Agent-with-Deepsek.git
cd Rag-Agent-with-Deepsek
```

#### 4ï¸âƒ£ Sanal Ortam OluÅŸturun

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/macOS
python3 -m venv venv
source venv/bin/activate
```

#### 5ï¸âƒ£ BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin

```bash
pip install -r requirements.txt
```

#### 6ï¸âƒ£ UygulamayÄ± BaÅŸlatÄ±n

```bash
streamlit run rag_deepsek.py
```

ğŸ‰ **TarayÄ±cÄ±nÄ±zda otomatik aÃ§Ä±lacaktÄ±r:** `http://localhost:8501`

---

## ğŸ“– KullanÄ±m

### 1. PDF YÃ¼kleme
1. Sol sidebar'daki **"PDF YÃ¼kle"** alanÄ±na dokÃ¼manÄ±nÄ±zÄ± sÃ¼rÃ¼kleyin
2. Otomatik iÅŸleme baÅŸlar (chunking + embedding)
3. âœ… BaÅŸarÄ± mesajÄ± gÃ¶rÃ¼nce hazÄ±r!

### 2. Soru Sorma
```
KullanÄ±cÄ±: "Bu dokÃ¼man ne hakkÄ±nda?"
AI: "Makine Ã¶ÄŸrenmesi, bilgisayarlara verilerden Ã¶ÄŸrenme yeteneÄŸi kazandÄ±ran..."
```

### 3. Retrieval Stats Ä°nceleme
- Expander'a tÄ±klayarak hangi chunks'Ä±n kullanÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz
- Top-10 sonucun preview'Ä±nÄ± inceleyin

### 4. Session YÃ¶netimi
- **ğŸ—‘ï¸ Sohbeti Temizle**: Sadece chat history'yi siler
- **ğŸ”„ VeritabanÄ±nÄ± SÄ±fÄ±rla**: TÃ¼m dokÃ¼man verisini temizler

---

## ğŸ”§ YapÄ±landÄ±rma

### Model DeÄŸiÅŸtirme

`rag_deepsek.py` dosyasÄ±nda:

```python
# LLM Modeli
LLM_MODEL_NAME = "deepseek-r1:8b"  # Alternatif: "llama2", "mistral"

# Embedding Modeli
EMBEDDING_MODEL_NAME = "mxbai-embed-large"  # Alternatif: "nomic-embed-text"
```

### Chunk Parametreleri

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # Daha bÃ¼yÃ¼k parÃ§alar iÃ§in artÄ±rÄ±n
    chunk_overlap=200,    # BaÄŸlam korunumu iÃ§in overlap
    add_start_index=True
)
```

### Top-K AyarÄ±

```python
related_docs = find_related_documents(prompt, k=10)  # k=15 veya k=20 deneyin
```

---

## ğŸ¨ Ekran GÃ¶rÃ¼ntÃ¼leri

### Ana ArayÃ¼z
```
ğŸ“š DocuMind AI
ğŸš€ GeliÅŸmiÅŸ DokÃ¼man Analiz AsistanÄ±

[Sidebar]              [Chat Area]
ğŸ“‚ Dosya Merkezi       ğŸ’¬ Sohbet
â””â”€ PDF YÃ¼kle          â””â”€ User: Makine Ã¶ÄŸrenmesi nedir?
â””â”€ ğŸ—‘ï¸ Temizle          â””â”€ AI: [DokÃ¼man bazlÄ± cevap]
â””â”€ ğŸ”„ SÄ±fÄ±rla          â””â”€ ğŸ“Š Retrieval Stats
```

---

## ğŸš¢ Deployment (Yerel SÄ±nÄ±rlama)

### âš ï¸ Streamlit Cloud'a Deploy Edilemez

Bu proje **Ollama** kullandÄ±ÄŸÄ± iÃ§in Streamlit Cloud'a deploy edilemez Ã§Ã¼nkÃ¼:
- âŒ Ollama yerel makine gerektir
- âŒ Streamlit Cloud sanal sunucularda Ã§alÄ±ÅŸÄ±r
- âŒ Modelleri cloud'a yÃ¼kleyemezsiniz

### âœ… Alternatif Deployment SeÃ§enekleri

#### 1. Docker ile Yerel Sunucu
```dockerfile
FROM python:3.10-slim

# Ollama kurulumu
RUN curl -fsSL https://ollama.com/install.sh | sh

# Proje kurulumu
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt

# Modelleri indir
RUN ollama pull deepseek-r1:8b
RUN ollama pull mxbai-embed-large

CMD ["streamlit", "run", "rag_deepsek.py"]
```

#### 2. Modal/Replicate Gibi GPU PlatformlarÄ±
- Ollama'yÄ± API modunda Ã§alÄ±ÅŸtÄ±rÄ±n
- Streamlit'i ayrÄ± deploy edin
- API Ã§aÄŸrÄ±larÄ± ile baÄŸlayÄ±n

#### 3. VPS/Dedicated Server
- DigitalOcean, Linode, AWS EC2
- GPU destekli instance seÃ§in
- Ollama + Streamlit kurun
- Reverse proxy (Nginx) ile yayÄ±nlayÄ±n

---

## ğŸ› ï¸ Teknik Detaylar

### Session State YÃ¶netimi
```python
# Kritik: Vector DB her re-run'da sÄ±fÄ±rlanmasÄ±n
if "vector_db" not in st.session_state:
    embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME)
    st.session_state.vector_db = InMemoryVectorStore(embeddings)
```

**Neden Ã–nemli?**
- Streamlit her etkileÅŸimde kodu baÅŸtan Ã§alÄ±ÅŸtÄ±rÄ±r
- Session state olmadan DB sÄ±fÄ±rlanÄ±r, veriler kaybolur
- Bu mimari sayede veriler oturumda kalÄ±cÄ± olur

### Prompt Engineering
```python
PROMPT_TEMPLATE = """
Sen, yalnÄ±zca saÄŸlanan dokÃ¼manlara dayanarak yanÄ±t veren titiz bir araÅŸtÄ±rma asistanÄ±sÄ±n. 
YanÄ±tlarÄ±nÄ± oluÅŸtururken dokÃ¼man dÄ±ÅŸÄ±na Ã§Ä±kma; eÄŸer aranan bilgi baÄŸlam iÃ§erisinde mevcut deÄŸilse, 
dÄ±ÅŸ bilgini kullanmak yerine 'Bu bilgi saÄŸlanan dÃ¶kÃ¼manlarda bulunmamaktadÄ±r' ÅŸeklinde belirt. 
CevaplarÄ±nÄ± olabildiÄŸince Ã¶z, teknik doÄŸruluÄŸu yÃ¼ksek ve maksimum 3 cÃ¼mle olacak ÅŸekilde yapÄ±landÄ±r.
"""
```

**Best Practices:**
- âœ… DokÃ¼man dÄ±ÅŸÄ±na Ã§Ä±kma engeli
- âœ… TÃ¼rkÃ§e native support
- âœ… KÄ±sa ve Ã¶z yanÄ±tlar (3 cÃ¼mle)
- âœ… Teknik doÄŸruluk vurgusu

---

## ğŸ“Š Performans

### Model BoyutlarÄ±
- **DeepSeek-R1 8B**: ~5.2 GB
- **mxbai-embed-large**: ~669 MB
- **Toplam**: ~6 GB

### Ä°ÅŸlem SÃ¼releri (Ortalama)
| Ä°ÅŸlem | SÃ¼re |
|-------|------|
| PDF Upload + Chunking | 2-5 saniye |
| Embedding + Indexing | 5-10 saniye |
| Query + Response | 3-8 saniye |

### RAM KullanÄ±mÄ±
- **Ä°lk BaÅŸlatma**: ~4 GB
- **Model YÃ¼klÃ¼**: ~6-8 GB
- **Query SÄ±rasÄ±nda**: ~7-9 GB

---

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! Ä°ÅŸte nasÄ±l:

1. Fork'layÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit'leyin (`git commit -m 'feat: Add amazing feature'`)
4. Push'layÄ±n (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

### ğŸ› Bug Bildirimi
[Issues](https://github.com/MustafaKocamann/Rag-Agent-with-Deepsek/issues) sayfasÄ±ndan bildirebilirsiniz.

---

## ğŸ“ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

---

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici

**Mustafa Kocaman**

- GitHub: [@MustafaKocamann](https://github.com/MustafaKocamann)
- LinkedIn: [Profiliniz]

---

## ğŸ™ TeÅŸekkÃ¼rler

- [Streamlit](https://streamlit.io/) - Harika framework
- [LangChain](https://www.langchain.com/) - RAG pipeline
- [Ollama](https://ollama.com/) - Yerel LLM desteÄŸi
- [DeepSeek](https://www.deepseek.com/) - GÃ¼Ã§lÃ¼ AI modeli

---

<div align="center">

**â­ Projeyi beÄŸendiyseniz yÄ±ldÄ±z vermeyi unutmayÄ±n!**

Made with â¤ï¸ and ğŸ¤– AI

</div>
